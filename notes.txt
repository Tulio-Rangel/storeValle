1. Pasos de configuración para el entorno de desarrollo.
- Iniciar el proyecto: npm init -y
- Crar los archivos: .gitignore, .eslintrc.json y .editorconfig
- Buscar en gitignore.io los ignore para node, windows, mac y linux y copiarlos en el .gitignore
- Agregar la configuración en el .editorconfig (uso la misma siempre)
- Agregar la configuracipon del .eslintrc.json (uso la misma siempre)
- Agregar los scripts en el package.json
- Verificar las dependencias globales que tengo instaladas (siempre hago esto porque se me olvidan) npm list -g --depth 0

2. Levantando el servidor.
- Instalar express
- Levantar el servidor (el básico es el hello world que el mismo express pone de ejemplo)

3. Construir la API.
- Crear las rutas de las distintas instancias
- Crear los servicios o controladores de las ruta ej: find, findById, etc.
- Poner en los controladores los status codes.
- Agregar asincronía a los controladores y en las rutas(?).
- Agregar captura de errores con try-catch.
- Crear carpeta de Middlewares y crear los primeros (o todos) los Middlewares.
- Instalar la libreria Boom para trabajar el manejo de errores npm i @hapi/boom
- Encontrar la documentación de las librerías npm docs <nombre de la libreria>
- Hacer validación de datos con Joi.
- Crear una caperta schemas o dtos y crear un archivo por cada entidad, ej: product.schema.js o product.dto.js
- Crear un archivo validatorHandler para crear las validaciones con el shcema que hicimos con Joi en el paso anterior.
- Otros Middlewares usados: cors: npm install cors
                            morgan: npm install morgan
                            helmet: npm install helmet
                            express debug: npm install express-debug --save-dev
                            express slash (sirve para no preocuparnos por poner slash en las rutas): npm install express-slash
                            passport: npm install passport
- Recomendaciones en las APIs: el uso de cors: const cors = require('cors'); app.use(cors()); [Así dejamos la api abierta a cualquier dominio]
                                https:
                                Proceso de Build:
                                Remover logs:
                                Seguridad con Helmet:
                                Testing

4. Deploy (en heroku).
- Crear cueta en heroku.
- Descargar e instalar el CLI de heroku.
- Instalación desde WSL o linux: curl https://cli-assets.heroku.com/install.sh | sh
- Desde la terminal WSL o linux: |heroku login| |heroku create| |git remote -v|
- Renombrar la app: heroku apps:rename <mi-api-rest>
- Seguir la documentación de heroku.
- Agregar el "engines" en el package.json y poner la versión de node en la que estamos trabajando.
- Correr el comando heroku local web para verificar cómo corre en local.
- Crear el archivo Procfile en la ruta principal y escribir web: npm run start (o el comando que tenga en los scripts para correr la app).
- Hacer commit y hacer push a heroku: git push heroku main
- Opcional: revisar cuando hayan errores internos: heroku logs --tail

5. Conexión a una BD (en este caso Postgres) con Docker.
- Crear el archivo docker-compose.yml y crear la configuración en el archivo.
- Levantar el contenedor y hacer la conexión desde la terminal (preferiblemente linux) con el comando: docker-compose up -d postgres (postgres puede ser reemplazado con cualquier nombre que le hayamos puesto al servicio).
- Podemos ver qué servicios tenemos levantados en docker con el comando: docker-compose ps
- Podemos parar nuestros servicios con el comando: docker-compose down y eso baja todo, si queremos bajar uno específico le agregamos el nombre del servicio luego del down.
- Al darle down al contenedor, nuestra info en la bd se va a perder, por eso debemos crear un volumen en el archivo docker-compose.yml para que que cada vez que levantemos el contenedor esta busque en la carpeta que referenciamos en el volumen y que vamos a crear, la bd.
- Para conectarnos al contenedor que creamos previamente, desde la terminal podemos correr el comando: docker-compose exec postgres bash (el postgres lo podemos cambiar por el nombre que le hayamos dado a nuestro servicio de docker).
- Luego corremos el comando: psql -h localhost -d my_store -U tulio (my_store y tulio los definimos en el archivo docker-compose).
- Para saber cómo es la estructura de nuestra bd, corremos el comando: \d+
- Para salirnos de la bd corremos el comando: \q
- Para salirnos de la conexión con postgres corremos el comando: exit (en este punto seguimos teniendo el contenedor arriba).
- También podemos conectarnos con una interfaz gráfica con PGadmin, esto lo podemos hacer por medio de una imagen en docker, debemos ir al docker-compose y agregar el servicio de pg admin.
- Debemos levantar el el servicio de pgadmin con el comando en la terminal: docker-compose up -d pgadmin
- Ingresamos en nuestro navegador la ruta del localhost que definimos para nuestro servicio de posgrest e ingresamos las credenciales que habíamos definido, y listo, tenemos nuestra interfaz gráfica.
- Debemos registrar un nuevo server en la interfaz gráfica, por nombre le podemos poner MyStore, luego en la pestaña de connection debemos colocar la dirección IP de nuestro contenedor (postgres).
- Así se obtiene la IP del contenedor: corremos el comando: docker ps, eso nos va a dar el id de nuestro contenedor, luego corremos el comando docker inspect y el id del contenedor que adquirimos previamente y ahí obtenemos el IPAdrress.
- Agregamos el IP obtenido, le ponemos el resto de credenciales que definimos en nuestro servicio de postgres.
- Le damos a save password y luego al último safe y listo de momento.
- En el botón query tools, creamos nuestra tabla.
CREATE TABLE tasks (
	id serial PRIMARY KEY,
	title VARCHAR ( 250 ) NOT NULL,
	completed boolean DEFAULT false
);

6. Conectando Postgres a Nodejs.
- Corremos el comando: npm install pg
- Creamos una nueva carpeta llamada libs, que es donde irán todas las librerías que usaremos donde haremos conexión con terceros, ejemplo, la base de datos.
- Creamos un archivo en la carpeta libs llamado postgres.js
- Seguimos la documentación, requerimos el Client de pg y con POO seteamos la configuración del nuevo client.
- Exportamos el getConnection a nuestros services y empezamos a desarrollar la logica de db en las distintas funciones.

7. Mejorando la conexión a la BD.
- Con la conexión anterior cada vez que hagamos una query haríamos una conexión y nos llenaríamos de conexiones, para eso mejoraremos la conexión.
- Creamos el archivo postgres.pool.js y hacemos las modificaciones que tenemos en el archivo de este repositorio.
- Hacemos los mismo que con el método anterior, solo que esta vez lo vamos a hacer en products para tener algo diferente.

8. Definiendo las Variables de Entorno.
- Crear una carpeta llamada config.
- Crear un archivo llamado config.js
- Crear las variables de entorno.
- Exportarlo a donde usemos datos que deberían estar ocultos.
- Codificar las variables con encodeURIComponent (Esto no hay que instalarlo) en los archivos donde usaremos el config.
- Dejar la conexión a la bd de forma que se pueda utilizar con una bd en linea como la de amazon.
- Creamos nuestro archivo .env y creamos un archivo .env.example para que otros desarrolladores puedan ver cuáles variables de entorno son necesarias en nuestro programa.
- Instalar el paquete: npm i dotenv
- Requerir dotenv en el archivo config así: require('dotenv').config();

9. Trabajando con ORM Sequelize.
- Instalar sequelize: npm install sequelize
- Instalar pg-hstore (recordar que estamos trabajando con postgress, revisar la documentación con las otras bd): npm i pg-hstore
- Crear un archivo llamado sequelize.js en la carpeta libs.
- Configurar el archivo con los datos de la db, en la instancia que crearemos debemos definir el 'dialecto' en el que estamos trabajando, en este caso postgres.

10. Creando los Modelos de la Base de Datos.
- Creamos una carpeta llamada bd y dentro una llamada models y ahí van los archivos con los modelos, tipo user.model.js
- Realizamos la configuración de nuestro archivo modelo.
- Creamos un archivo index.js en la carpeta models.
- Todos los modelos los vamos a importar en el archivo index.js de la carpeta models.
- Exportamos nuestro setUpModels del archivo index.js de la carpeta models y lo importamos en nuestro archivo sequelize.
- Como en este primer ejemplo creamos una tabla para usuarios, vamos a actualizar la conexión a bd de usuarios en el archivo user.service.js
- Creamos el resto de funciones CRUD y el resto de modelos de nuestra API.
- Creo el errorhandler del orm en el archivo error handler.

11. Cambiando la Base de Datos a MySQL.
- Agregamos los mismo datos de postgress pero esta vez con datos de MySQL en el archivo docker-compose.
- Para tener interfaz gráfica creamos una imagen de phpMyAdmin en docker, los datos están en el archivo docker.compose.
- Levantamos el servicio de mysql: docker-compose up -d mysql
- Verificamos que el servicio esté arriba con: docker-compose ps
- Levantar el servicio de phpmyadmin: docker-compose up -d phpmyadmin
- instalar la dependencia de mysql: npm i mysql2
- En nuestro archivo .env cambiamos el puerto por el que ahora usamos en mysql y el db user por root.
- En nuestroa archivo libs/sequelize.js cambiamos la uri que empieza por postgress y le ponemos mysql y lo mismo en la linea donde dice el dialecto, le ponemos mysql.

12. Haciendo Migraciones.
- Instalar la dependencia sequelize-cli como una dependencia de desarrollo: npm i sequelize-cli -D
- Se crea un archivo fuera llamado .sequelizerc y se agregan los datos que están en ese archivo.
- En la carpeta db creamos 2 carpetas más llamadas seeders y migrations y un archivo config.js.
- Llenamos el archivo config.js de la carpeta db con la info que está en el archivo actualmente.
- En el archivo anterior, en el module.export colocamos los ambientes que vamos a usar (desarrollo, producción, etc).
- En el archivo package.json vamos a agregar un nuevo sccript llamado migrations:generate y le vamos a poner la instrucción sequelize-cli migration:generate --name
- Para correr lo anterior, en la terminal corremos: npm run migrations:generate y el nombre, en este caso será create-user quedando así: npm run migrations:generate create-user
- Lo anterior crea un archivo en nuestra carpeta de migraciones de nuestra carpeta db.
- Eliminaremos la linea de código que dice que sincronice en el archivo sequelizr de nuestra carpeta libs.
- Importamos el schema y la tabla en el archivo de migración generado.
- En el up ponemos como queremos que se cree la tabla.
- En el down ponemos el reverso de lo anterior, es decir eliminar la tabla.
- En este archivo podríamos colocar todas las migraciones, no solo la del usuario.
- En las migraciones se pueden hacer más cosas que crear tablas, pero de momento ese es el ejemplo más básico.
- En el package.json creamos un nuevo script:  "migrations:run": "sequelize-cli db:migrate"
- El anterior script es para ahora correr la migración que creamos.
- Y creamos un script para el revert:  "migrations:revert": "sequelize-cli db:migrate:undo"
- Si corremos el comando de la migración y luego nos vamos a pgadmin, veremos que se creó también una tabla llamada SequeliMeta, esta tabla lleva el histórico de las migraciones.

13. Agregando Columnas a una Tabla ya Establecida.
- Nos vamos al archivo del modelo y agregamos el nuevo campo que queremos agregar, en este caso, al modelo de usuarios le agregamos el rol.
- Corremos en la terminal el siguiente comando: npm run migrations:generate add-role
- Agregamos la info tal como está en el archivo para agregar la columna nueva.
- Recordemos que en el archivo del esquema de usuarios tenemos el rol comentado, debemos descomentarlo para que todo trabaje bien.
- Corremos el script de la migración : npm run migrations:run Esta va a correr solo la migración que acabos de hacer, solo va a agregar la nueva columna porque en su memoria ya corrió la migración para crear la tabla.
- Ahora podemos testear creando usuarios con el nuevo rol.
- En el esquema de usuario dejé comentado en la creación de usuario que el rol fuera requerido para probar que si se pusiera customer por defecto y sí lo hace.

14. Relaciones Uno a Uno.
- Primero tenemos que crear nuevas entidades ya que solo tenemos la de usuarios, en este caso creamos una para customer.
- Creamos el modelo de customer, modificamos el archivo index de la carpeta models y agregamos los datos correspondientes de customer.
- Creamos el archivo customer.service.js
- Creamos el archivo customer.router.js y hacemos su respectiva referencia en el archivo index de la carpeta routes
- Creamos el archivo customer.schema.js
- Para definir la relación lo hacemos en el archivo model, en la función associate, en este caso lo hacermos en el archivo del customer con un belongsTo.
- En el archivo index de la carpeta models terminamos la asiciación con la siguiente linea  Customer.associate(sequelize.models);
- En el archivo del modelo del customer debemos agregar también esa relación, por eso le agregamos la columna userId (esta va a ser una foreign key).
- En esa misma columna hay una línea llamada reference, eso es porque tenemos que hacer referencia a la tabla que va a hacer referencia, valga la redundancia, en este caso customer va a hacer referencia a users.
- Creamos la migración para la tabla customer: npm run migrations:generate create-customers
- Modificamos el archivo generado con los datos de customer.
- Corremos el script de migrations:run
- De momento en insomnia si hacemos get a los customer este nos va a mostrar el id de usuario de dicho customer, pero nosotros queremos es la info de dichi usuario, para eso nos vamos al servicio de customer y en el findAll vamos a agregar un includ que nosotros ya definimos en el modelo de customer como "as: 'user'", esto lo agregamos como un array dentro de un objeto, un array porque podemos tener varias relaciones en el customer, pero de mosmento la unica relación que tenemos es con user.
- Ahora vamos a hacer la relación uno a uno de forma bidireccional, entonces nos vamos al modelo de usuarios y trabajamos en la función associate.
- Agregamos la asociación en el index de la carpeta models
- En el servicio de usuarios agregamos el include en el findAll para que nos resuelva el customer.
- Vamos a modificar el customer de forma que podamos crear el usuario desde el customer, para eso nos vamos al schema de customer y modificamos la parte donde pedimos el userId y ahí vamos a requerir ahora los datos del usuario, no el id (esto es el código que tenía comentado antes), vamos a dejar el userId solo para la parte de actualización.
- En el servicio de customer modificamos el crear, creando primero al usuario: const newUser = await models.User.create(data.user); y luego modificando un poco el código del customer.
- El código anterior queda más sencillo de la siguiente forma: const newCustomer = await models.Customer.create(data, {include: ['user'],});

15. Relación Uno a Muchos.
- Empezamos creando los schemas de category y products.
- Creamos los archivos de model para products y categories.
- En el archivo model de category, en la asociación pondremos hasMany porque una categoría puede tener muchos productos y el categoryId será la foreigKey que recibirá la parte del products porque así lo definimos en el modelo de products.
- Por parte del archivo model de producst, esta debe ser belongsTo en la asociación porque el producto pertenece a X categoría (Products es quien carga con la relación).
- Actualizamos el index del model con los datos de category y products.
- Creamos una nueva migración para crear las nuevas tablas.
- Corremos la nueva migración y verificamos que sí se hayan creado las tablas.
- Ahora sí trabajamos en el servicio de categories.
- Modificamos el servicio de products ya que antes estaba almacenado en memoria y ahora lo queremos en nuestra base de datos.
- Debemos modificar el schema de products para poder asignar categorias desde la creación de productos.

16. Relación Muchos a Muchos.
- Un producto puede estar en muchas órdenes de compra y una órden de compra puede tener muchos productos.
- Empezamos creando una relacion uno a muchos entre órdenes y customer porque un customer puede tener muchas ordenes.
- Creamos el modelo de órdenes.
- Modificamos el archivo customer model para agregar la relación con el modelo de ordenes en la función de associate.
- Agregamos los datos de order en el archivo index de la carpeta model.
- Creamos la migración para crear la tabla de ordenes.
- Ejecutamos la migración y vemos en pgadmin que se haya hecho.
- Modificamos/creamos el servicio de orders.
- Creamos el orderSchema si aun no lo tenemos.
- Creamos/modificamos el router de orders.
- Probamos que todo vaya bien.
- INICIO DE LA RELACIÓN MUCHOS MUCHOS.
- Creamos una tabla intermedia llamada order-product, para esto iniciamos con el modelo.
- Hacemos la migración para crear la tabla.
- Actualizamos el archivo generado del migrations.
- Corremos la migración y revisamos en pgadmin que se haya creado la tabla.
- Agregamos los datos de la nueva tabla al index de la carpeta model.
- En el modelo de order, agregamos la relación con OrderProduct con un has many.
- Creamos un schema para order-product, pero lo crearemos en el archivo de order porque igual es una orden, pero se puede hacer por separado sin ningún problema.
- Al router de order le crearemon un nuevo endpoint para agregar los items, no olvidad también importar el schema que creamos.
- En el service de order creamos una nueva función que sea para agregar el item, para poder usarla en el nuevo endpoint que creamos de items en orders.
- En el servicio de orders, en el findOne, también vamos a agregar la asociación de items, para que tambipen nos traiga los items de la orden de compra.
- Sequelize nos permite sacar el total de la orden de compra, esto se hace en el modelo, pero no se guarda en la tabla de la bd pasando el dato como tipo virtual.

17. Paginación.
- ¿Qué es el limit? es la cantidad de elementos que quiero que me traiga la consulta.
- ¿Qué es el offset? es como un apuntador, si lo dejamos en 0 es como la primera poscición de un array, si el limit es 2, este me trae los dos primeros elementos, pero la siguiente página, el offset sería 2 y me traería los elementos 3 y 4.
- Agregamos el limit y el offset al service de product en el find all.
- Agregamos también las respectivas queryparams(?) de limir y offset en el schema de product.
- Requerimos lo anterior en el roter de products, en el get obviamente.
- En el service de product en el find modificamos la función para hacer dinámico el limit y el offset con una const llamada options y con un if en caso de recibir el limit y el offset en la query.

18. Realizar filtro por precio.
- En el schema de products en el queryProductSchema, podemos colocar más parametros opcionales, esta vez pondremos también el precio que ya lo tenemos definido.
- Modificamos el service en el find para poder trabajar cuando recibimos el precio.

19. Realizar filtro por rango de precio.
- En el schema de products creamos 2 Joi nuevos llamados price_min y price_max y lo agregamos al schema opcional que venimos trabajando.
- Modificamos el service de product en el find para cuando el query reciba los precios.

20. Deplegrar en producción la API en Heroku.
- Nos aseguramos que tengamos conectado en el repositorio remoto de Heroku, sino lo conectamos con: git remote heroku to nombreDelRepoDeHeroku
- En la terminal corremos el comando: heroku addons:create heroku-postgresql:hobby-dev [Porque esa es la capa gratuita]
- Para ver la documentación (esto sale si lo anterior funciona): heroku addons:docs heroku-postgresql
- Para la info de nuestra bd corremos el siguiente comando: hero pg:info
- Modificamos nuestro archivo .env para agregar la variable de entorno que nos pide Heroku que es DATABASE_URL
- En nuestro archivo config creamos un nuevo entorno llamado isProd que es para producción y una variable que lea nuestra nueva variable de database.
- En el archivo postgres.pool está un ejemplo de cómo hacer con la conexión de la bd cuando está en desarrollo y cuando está en producción.
- En el archivo sequelize está de la forma con una sola URL sea desarrollo o Producción.
- Heroku nos pide unas modificaciones en la conexión con la bd, como el ssl, que agregamos al archivo.
- Se modifica también el archivo config de las migraciones por el tema de la URL de Heroku.
- Creamos una rama llamada producción, aunque por lo general main es la rama producción, pero ajá.
- Hacemos push a heroku de la siguiente forma, para que quede en la rama main de heroku: git push heroku production:main
- Aquí hasta el momento ya subimos lo que necesitábamos a Heroku, pero nos faltan las migraciones, por lo que nos toca correr el siguiente comando: heroku run npm run migrations:run para que corra todas las migraciones que hemos hecho hasta ahora.
- Se debe poner sequelize-CLI como una dependencia de producción para hacer lo anterior, antes la teníamos como una dependencia de desarrllo.
- La migración no nos va a servir por el tema de que nosotros agregamos la columna rol después de crear la tabla users, en ese caso, eliminaremos el archivo de la migración donde se agrega la columna para poder correr la migración.
- Para sacar el total de productos usamos un datatype virtual, pero esto nos da un error, por lo que nos toca modificar la migración.
- Nos vamos al archivo de migracipón de order y modificamos el archivo.
- La URL del delploy es https://storevalle.herokuapp.com

21. Agregando Middlewares
- Crearemos un nuevo archivo middleware para la autenticación, llamado auth.handler.js por ahora será para consumir otras APIs, pero de forma de ejemplo.
- Exportamos la función chekApiKey al index general y la utilizamos para proteger el endpoint de nueva ruta, probamos en insomnia que funcione poniendo el header de api y el valor 123.
- Cambiamos la API Key quemada por una variable de entorno.
- En el archivo .env creamos la variable API_KEY y le asignamos el valor.
- Agregamos esta nueva variable de entorno a nuestro archivo config.
- Importamos el config en el middleware que creamos y lo usamos en el valor de la apikey.
- Cada vez que se cambie una variable de entorno hay que reiniciar el servidor ya que las variables de entorno no tienen live loading.

22. Hashing a las contraseñas.
- Instalar bcrypt: npm i bcrypt
- Ir al servicio de usuario a crear el hash.
- Probamos en insomnia.
- Para que no nos retorne el password al crear el nuevo usuario, agregamos una propiedad llamada delete.
- También debemos agregar el hash al servicio de customer, pero este es diferente ya que el usuario está anidado.

23. Login con Passport.js
- Instalar passport y la estrategia passport-local: npm i passport passport-local la estrategia local es para hacer login local, existen otras estrategias como la de facebook, etc.
- Creamos la carpeta utils si aun no la tenemos, dentro de esa carpeta creamo una carpeta llamada auth un archivo index.js y también dentro de esa carpeta una carpeta llamada strategies.
- Dentro de la carpeta strategies creamos el primer archivo, local.strategy.js
- Importamos la librería passport-local, creamos una nueva instancia de la strategy y la exportamos.
- En el index.js de strategies requerimos passport y ahí es donde vamos a indicar las estrategias que vamos a utilizar.
- Antes de seguir, debemos crear en nuestro servicio de usuario un find by email para que vaya junto al password.
- Requerimos el user service en nuestro archivo de estrategia local.
- Requerimos bcrypt
- creamos la función para que compare el hash con la contraseña del usuario.
- Creamos una nueva ruta, en este caso la llamaremos auth.
- La requerimos en el index de los routers.

24. Implementar JWT.
- Instalar la libreria para JWT: npm install jsonwebtoken
- Importamos jwt en nuestro router de auth.
- Creamo una variable de entorno del secret, lo agregamos en nuestro config.
- El secret lo podemos crear en keygen.io o https://randomkeygen.com/ en la opción WEP 256-bit key para tener un secret pro.
- Creamos el codigo para firmar el token en el router del login.

25. Requerir el Token Desde las Otras Rutas.
- Instalar passport-jwt: npm install passport-jwt
- Creamos una nueva strategia de auth llamada jwt.strategy.js
- Importar los métodos Strategy y ExtractJwt de la librería.
- Requerimos el config para el secret.
- Creamos nuestras options que le vamos a pasar.
- y creamos la estrategia.
- Importamos la nueva estrategia en el index de las estrategias.
- Pasamos a agregar este jwt en los campos que queremos que tengan jwt, en este caso será el de crear categorías.
- Para eso importamos passport y agragamos el passport en el método que deseamos.

26. Recibiendo los Roles por los JWT
- Crear la función checkAdminRole en el middleware auth.handler
- La importamos en donde la vayamos a implemetar.
- Redefinimos la función a checkRole para no tener que crear un middleware por cada rol.

27. Obteniendo Órdenes Según el Perfil que esté Autenticado.
- Crear el archivo profile.router.js
- Creamos un nuevo servicio en el service de ordenes llamado findByuser
- Añadimos el router a nustro index de routers.

28. Crear Órdenes de compra cuando ya el usuario está autenticado.
- Se comenta o elimina la linea en donde está el validatorHandler porque ahora lo va a recibir por el sub.
- Se modifica la linea del const body porque ahora no vendrá del req.body sino del sub.
- Se debe agregar el passport validator entonces.
- En el service de order modificamos el create tal como quedó en el código.

29. Enviar Correos con Nodejs
- Instalar nodemailer: npm install nodemailer
- Creamos un usuario de pruebas en https://ethereal.email/
- Se le da en crear cuenta
- Se copia desde el puerto (port) hasta el auth (todo el objeto) en la variable transporter y ya no necesirariamos la función de create.
- Configurando Gmail para el servicio smtp:
- Nos vamos a Gmail, en account o cuenta, luego a seguridad, se debe tener activa la verificación en 2 pasos.
- Le damos en contraseñas de otras aplicaciones
- En seleccionar aplicación le damos a otra y le ponemos como nombre NodeApp y le damos a generar.
- Eso nos va a dar una contraseña que es la que pondremos en el auth.
- El host de smtp lo cambiamos a gmail.com
- El secure lo cambiamos a true
- Cambiamos el puerto a 465
- Cambiamos el user a nuestro correo de Gmail.
- El usuario y la variable deberían estar como variables de entorno.

30. Implementando el Envío de Emails (Recovery Password).
- En el router de auth creamos un nuevo endpoint llamado recovery.
- No necesitamos el passport.authenticate porque el usuario no está autenticado. Duh!
- Como tenemos muicha lógica de auth regada por ahí, creamos un servicio para auth.
- Cambiamos la configuración del local strategy:
- Cambiamos el user service por auth service en nuestra local strategy.
- Requerimos el auth service en el auth router.
- Modificamos el endpoint de login ya que ahora esa lógica la tenemos en el service.
- Terminamos de crear la lógica de la ruta de recovery.

31. Generando Link de Recuperación.
- Refactorizamos el código del servcie donde enviamos el email y lo dividimos en 2 uno para recovery y otro para el envio general.
- Empezamos a redactar el correo de recuperar contraseña.
- Esta vez debemos guardar el token en la bd para evitar que nos envien tokens falsos... Aunque igual si no corresponde con la firma no va a servir, pero ajá, más seguridad.
- Corremos la migración: npm run migrations:generate recovery-token-field
- Debemos modificar el user model para agregar la nueva columna.
- En el archivo generado de la migración, agragamos el código necesario para hacer la adición de la columna.
- Corremos la migración con: npm run migrations:run
- En nuestro auth service en el sendRecovery ya que tenemos el service de user, utilizaremos el service de update del user porque vamos a actualizar su entrada, no a crear una nueva.

32. Validando el Token para Recuperar Contraseña.
- Creamos un nuevo endpoint en nuestro router de auth llamado change-password.
- En el Service de auth creamos un nuevo método que se llame changePassword.
- Debemos cambiar el retorno del login ya que nos está devolviendo el recovery token.
- Para eso agragamos un linea de código al getUser del auth Service: delete user.dataValues.recoveryToken;
- Ya aquí podemos deplegar en Heroku.
- Verificamos que nuestras variables de entorno estén en Heroku.
- corremos el comando para borrar las migraciones en Heroku (Esto no se hace si ya está en producción).
- Hacemos push a Heroku.
- Corremos las migraciones en Heroku.
