1. Pasos de configuración para el entorno de desarrollo.

- Iniciar el proyecto: npm init -y
- Crar los archivos: .gitignore, .eslintrc.json y .editorconfig
- Buscar en gitignore.io los ignore para node, windows, mac y linux y copiarlos en el .gitignore
- Agregar la configuración en el .editorconfig (uso la misma siempre)
- Agregar la configuracipon del .eslintrc.json (uso la misma siempre)
- Agregar los scripts en el package.json
- Verificar las dependencias globales que tengo instaladas (siempre hago esto porque se me olvidan) npm list -g --depth 0

2. Levantando el servidor.

- Instalar express
- Levantar el servidor (el básico es el hello world que el mismo express pone de ejemplo)

3. Construir la API.
- Crear las rutas de las distintas instancias
- Crear los servicios o controladores de las ruta ej: find, findById, etc.
- Poner en los controladores los status codes.
- Agregar asincronía a los controladores y en las rutas(?).
- Agregar captura de errores con try-catch.
- Crear carpeta de Middlewares y crear los primeros (o todos) los Middlewares.
- Instalar la libreria Boom para trabajar el manejo de errores npm i @hapi/boom
- Encontrar la documentación de las librerías npm docs <nombre de la libreria>
- Hacer validación de datos con Joi.
- Crear una caperta schemas o dtos y crear un archivo por cada entidad, ej: product.schema.js o product.dto.js
- Crear un archivo validatorHandler para crear las validaciones con el shcema que hicimos con Joi en el paso anterior.
- Otros Middlewares usados: cors: npm install cors
                            morgan: npm install morgan
                            helmet: npm install helmet
                            express debug: npm install express-debug --save-dev
                            express slash (sirve para no preocuparnos por poner slash en las rutas): npm install express-slash
                            passport: npm install passport
- Recomendaciones en las APIs: el uso de cors: const cors = require('cors'); app.use(cors()); [Así dejamos la api abierta a cualquier dominio]
                                https:
                                Proceso de Build:
                                Remover logs:
                                Seguridad con Helmet:
                                Testing

4. Deploy (en heroku).
- Crear cueta en heroku.
- Descargar e instalar el CLI de heroku.
- Instalación desde WSL o linux: curl https://cli-assets.heroku.com/install.sh | sh
- Desde la terminal WSL o linux: |heroku login| |heroku create| |git remote -v|
- Renombrar la app: heroku apps:rename <mi-api-rest>
- Seguir la documentación de heroku.
- Agregar el "engines" en el package.json y poner la versión de node en la que estamos trabajando.
- Correr el comando heroku local web para verificar cómo corre en local.
- Crear el archivo Procfile en la ruta principal y escribir web: npm run start (o el comando que tenga en los scripts para correr la app).
- Hacer commit y hacer push a heroku: git push heroku main
- Opcional: revisar cuando hayan errores internos: heroku logs --tail

5. Conexión a una BD (en este caso Postgres) con Docker.
- Crear el archivo docker-compose.yml y crear la configuración en el archivo.
- Levantar el contenedor y hacer la conexión desde la terminal (preferiblemente linux) con el comando: docker-compose up -d postgres (postgres puede ser reemplazado con cualquier nombre que le hayamos puesto al servicio).
- Podemos ver qué servicios tenemos levantados en docker con el comando: docker-compose ps
- Podemos parar nuestros servicios con el comando: docker-compose down y eso baja todo, si queremos bajar uno específico le agregamos el nombre del servicio luego del down.
- Al darle down al contenedor, nuestra info en la bd se va a perder, por eso debemos crear un volumen en el archivo docker-compose.yml para que que cada vez que levantemos el contenedor esta busque en la carpeta que referenciamos en el volumen y que vamos a crear, la bd.
- Para conectarnos al contenedor que creamos previamente, desde la terminal podemos correr el comando: docker-compose exec postgres bash (el postgres lo podemos cambiar por el nombre que le hayamos dado a nuestro servicio de docker).
- Luego corremos el comando: psql -h localhost -d my_store -U tulio (my_store y tulio los definimos en el archivo docker-compose).
- Para saber cómo es la estructura de nuestra bd, corremos el comando: \d+
- Para salirnos de la bd corremos el comando: \q
- Para salirnos de la conexión con postgres corremos el comando: exit (en este punto seguimos teniendo el contenedor arriba).
- También podemos conectarnos con una interfaz gráfica con PGadmin, esto lo podemos hacer por medio de una imagen en docker, debemos ir al docker-compose y agregar el servicio de pg admin.
- Debemos levantar el el servicio de pgadmin con el comando en la terminal: docker-compose up -d pgadmin
- Ingresamos en nuestro navegador la ruta del localhost que definimos para nuestro servicio de posgrest e ingresamos las credenciales que habíamos definido, y listo, tenemos nuestra interfaz gráfica.
- Debemos registrar un nuevo server en la interfaz gráfica, por nombre le podemos poner MyStore, luego en la pestaña de connection debemos colocar la dirección IP de nuestro contenedor (postgres).
- Así se obtiene la IP del contenedor: corremos el comando: docker ps, eso nos va a dar el id de nuestro contenedor, luego corremos el comando docker inspect y el id del contenedor que adquirimos previamente y ahí obtenemos el IPAdrress.
- Agregamos el IP obtenido, le ponemos el resto de credenciales que definimos en nuestro servicio de postgres.
- Le damos a save password y luego al último safe y listo de momento.
- En el botón query tools, creamos nuestra tabla.
CREATE TABLE tasks (
	id serial PRIMARY KEY,
	title VARCHAR ( 250 ) NOT NULL,
	completed boolean DEFAULT false
);

6. Conectando Postgres a Nodejs.
- Corremos el comando: npm install pg
- Creamos una nueva carpeta llamada libs, que es donde irán todas las librerías que usaremos donde haremos conexión con terceros, ejemplo, la base de datos.
- Creamos un archivo en la carpeta libs llamado postgres.js
- Seguimos la documentación, requerimos el Client de pg y con POO seteamos la configuración del nuevo client.
- Exportamos el getConnection a nuestros services y empezamos a desarrollar la logica de db en las distintas funciones.

7. Mejorando la conexión a la BD.
- Con la conexión anterior cada vez que hagamos una query haríamos una conexión y nos llenaríamos de conexiones, para eso mejoraremos la conexión.
- Creamos el archivo postgres.pool.js y hacemos las modificaciones que tenemos en el archivo de este repositorio.
- Hacemos los mismo que con el método anterior, solo que esta vez lo vamos a hacer en products para tener algo diferente.

8. Definiendo las Variables de Entorno.
- Crear una carpeta llamada config.
- Crear un archivo llamado config.js
- Crear las variables de entorno.
- Exportarlo a donde usemos datos que deberían estar ocultos.
- Codificar las variables con encodeURIComponent (Esto no hay que instalarlo) en los archivos donde usaremos el config.
- Dejar la conexión a la bd de forma que se pueda utilizar con una bd en linea como la de amazon.
- Creamos nuestro archivo .env y creamos un archivo .env.example para que otros desarrolladores puedan ver cuáles variables de entorno son necesarias en nuestro programa.
- Instalar el paquete: npm i dotenv
- Requerir dotenv en el archivo config así: require('dotenv').config();

9. Trabajando con ORM Sequelize.
- Instalar sequelize: npm install sequelize
- Instalar pg-hstore (recordar que estamos trabajando con postgress, revisar la documentación con las otras bd): npm i pg-hstore
- Crear un archivo llamado sequelize.js en la carpeta libs.
- Configurar el archivo con los datos de la db, en la instancia que crearemos debemos definir el 'dialecto' en el que estamos trabajando, en este caso postgres.

10. Creando los Modelos de la Base de Datos.
- Creamos una carpeta llamada bd y dentro una llamada models y ahí van los archivos con los modelos, tipo user.model.js
- Realizamos la configuración de nuestro archivo modelo.
- Creamos un archivo index.js en la carpeta models.
- Todos los modelos los vamos a importar en el archivo index.js de la carpeta models.
- Exportamos nuestro setUpModels del archivo index.js de la carpeta models y lo importamos en nuestro archivo sequelize.
- Como en este primer ejemplo creamos una tabla para usuarios, vamos a actualizar la conexión a bd de usuarios en el archivo user.service.js
- Creamos el resto de funciones CRUD y el resto de modelos de nuestra API.
- Creo el errorhandler del orm en el archivo error handler.

11. Cambiando la Base de Datos a MySQL.
- Agregamos los mismo datos de postgress pero esta vez con datos de MySQL en el archivo docker-compose.
- Para tener interfaz gráfica creamos una imagen de phpMyAdmin en docker, los datos están en el archivo docker.compose.
- Levantamos el servicio de mysql: docker-compose up -d mysql
- Verificamos que el servicio esté arriba con: docker-compose ps
- Levantar el servicio de phpmyadmin: docker-compose up -d phpmyadmin
- instalar la dependencia de mysql: npm i mysql2
- En nuestro archivo .env cambiamos el puerto por el que ahora usamos en mysql y el db user por root.
- En nuestroa archivo libs/sequelize.js cambiamos la uri que empieza por postgress y le ponemos mysql y lo mismo en la linea donde dice el dialecto, le ponemos mysql.

12. Haciendo Migraciones.
- Instalar la dependencia sequelize-cli como una dependencia de desarrollo: npm i sequelize-cli -D
- Se crea un archivo fuera llamado .sequelizerc y se agregan los datos que están en ese archivo.
- En la carpeta db creamos 2 carpetas más llamadas seeders y migrations y un archivo config.js.
- Llenamos el archivo config.js de la carpeta db con la info que está en el archivo actualmente.
- En el archivo anterior, en el module.export colocamos los ambientes que vamos a usar (desarrollo, producción, etc).
- En el archivo package.json vamos a agregar un nuevo sccript llamado migrations:generate y le vamos a poner la instrucción sequelize-cli migration:generate --name
- Para correr lo anterior, en la terminal corremos: npm run migrations:generate y el nombre, en este caso será create-user quedando así: npm run migrations:generate create-user
- Lo anterior crea un archivo en nuestra carpeta de migraciones de nuestra carpeta db.
- Eliminaremos la linea de código que dice que sincronice en el archivo sequelizr de nuestra carpeta libs.
- Importamos el schema y la tabla en el archivo de migración generado.
- En el up ponemos como queremos que se cree la tabla.
- En el down ponemos el reverso de lo anterior, es decir eliminar la tabla.
- En este archivo podríamos colocar todas las migraciones, no solo la del usuario.
- En las migraciones se pueden hacer más cosas que crear tablas, pero de momento ese es el ejemplo más básico.
- En el package.json creamos un nuevo script:  "migrations:run": "sequelize-cli db:migrate"
- El anterior script es para ahora correr la migración que creamos.
- Y creamos un script para el revert:  "migrations:revert": "sequelize-cli db:migrate:undo"
- Si corremos el comando de la migración y luego nos vamos a pgadmin, veremos que se creó también una tabla llamada SequeliMeta, esta tabla lleva el histórico de las migraciones.

13. Agregando Columnas a una Tabla ya Establecida.
- Nos vamos al archivo del modelo y agregamos el nuevo campo que queremos agregar, en este caso, al modelo de usuarios le agregamos el rol.
- Corremos en la terminal el siguiente comando: npm run migrations:generate add-role
- Agregamos la info tal como está en el archivo para agregar la columna nueva.
- Recordemos que en el archivo del esquema de usuarios tenemos el rol comentado, debemos descomentarlo para que todo trabaje bien.
- Corremos el script de la migración : npm run migrations:run Esta va a correr solo la migración que acabos de hacer, solo va a agregar la nueva columna porque en su memoria ya corrió la migración para crear la tabla.
- Ahora podemos testear creando usuarios con el nuevo rol.
- En el esquema de usuario dejé comentado en la creación de usuario que el rol fuera requerido para probar que si se pusiera customer por defecto y sí lo hace.
